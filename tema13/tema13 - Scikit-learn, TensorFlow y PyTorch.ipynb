{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 14: Librer√≠as de Big Data e IA - Parte 2\n",
    "## Teor√≠a y Ejemplos\n",
    "\n",
    "### Contenido\n",
    "5. Scikit-learn - Machine Learning\n",
    "6. TensorFlow/Keras - Deep Learning\n",
    "7. PyTorch - Deep Learning Avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Scikit-learn - Machine Learning\n",
    "\n",
    "**Scikit-learn** es la librer√≠a m√°s popular para Machine Learning en Python.\n",
    "\n",
    "### ¬øPor qu√© Scikit-learn?\n",
    "- **Completo:** Algoritmos de clasificaci√≥n, regresi√≥n, clustering, etc.\n",
    "- **Consistente:** API uniforme para todos los algoritmos\n",
    "- **Documentaci√≥n:** Excelente documentaci√≥n y ejemplos\n",
    "- **Integraci√≥n:** Funciona con NumPy, Pandas y Matplotlib\n",
    "- **Producci√≥n:** C√≥digo optimizado y listo para producci√≥n\n",
    "\n",
    "### Instalaci√≥n\n",
    "```bash\n",
    "pip install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Flujo de Trabajo de Machine Learning\n",
    "\n",
    "```python\n",
    "1. Cargar y explorar datos\n",
    "2. Preparar datos (limpieza, normalizaci√≥n)\n",
    "3. Dividir en train/test\n",
    "4. Entrenar modelo\n",
    "5. Hacer predicciones\n",
    "6. Evaluar modelo\n",
    "7. Ajustar hiperpar√°metros\n",
    "8. Modelo final\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Regresi√≥n Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Preparar datos\n",
    "X = tips[['total_bill']].values  # Variable independiente\n",
    "y = tips['tip'].values           # Variable dependiente\n",
    "\n",
    "# Dividir en train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape[0]}\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]}\")\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "modelo = LinearRegression()\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nCoeficiente (pendiente): {modelo.coef_[0]:.4f}\")\n",
    "print(f\"Intercepto: {modelo.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== M√âTRICAS DE EVALUACI√ìN ===\")\n",
    "print(f\"MSE (Error Cuadr√°tico Medio): {mse:.4f}\")\n",
    "print(f\"RMSE (Ra√≠z del MSE): {rmse:.4f}\")\n",
    "print(f\"MAE (Error Absoluto Medio): {mae:.4f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"\\nInterpretaci√≥n: El modelo explica el {r2*100:.1f}% de la varianza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Gr√°fico 1: L√≠nea de regresi√≥n\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test, y_test, alpha=0.6, label='Datos reales')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicci√≥n')\n",
    "plt.xlabel('Cuenta Total ($)')\n",
    "plt.ylabel('Propina ($)')\n",
    "plt.title('Regresi√≥n Lineal: Cuenta vs Propina')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 2: Predicciones vs valores reales\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], \n",
    "         [y_test.min(), y_test.max()], \n",
    "         'r--', linewidth=2, label='Predicci√≥n perfecta')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.title('Valores Reales vs Predicciones')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Clasificaci√≥n - Regresi√≥n Log√≠stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar dataset de iris\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Crear DataFrame para mejor visualizaci√≥n\n",
    "iris_df = pd.DataFrame(\n",
    "    data=iris.data,\n",
    "    columns=iris.feature_names\n",
    ")\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map(\n",
    "    {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    ")\n",
    "\n",
    "print(\"Dataset Iris (primeras 10 filas):\")\n",
    "print(iris_df.head(10))\n",
    "\n",
    "print(f\"\\nForma: {iris_df.shape}\")\n",
    "print(f\"\\nDistribuci√≥n de especies:\")\n",
    "print(iris_df['species_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Entrenar modelo\n",
    "modelo_clf = LogisticRegression(max_iter=200)\n",
    "modelo_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = modelo_clf.predict(X_test)\n",
    "\n",
    "# Evaluar\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisi√≥n (Accuracy): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n=== REPORTE DE CLASIFICACI√ìN ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names)\n",
    "plt.title('Matriz de Confusi√≥n - Clasificaci√≥n de Iris', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. √Årboles de Decisi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Entrenar √°rbol de decisi√≥n\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    max_depth=3, \n",
    "    random_state=42\n",
    ")\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"Precisi√≥n del √Årbol: {accuracy_tree:.4f} ({accuracy_tree*100:.2f}%)\")\n",
    "\n",
    "# Visualizar √°rbol\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree_model, \n",
    "          feature_names=iris.feature_names,\n",
    "          class_names=iris.target_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title('√Årbol de Decisi√≥n - Clasificaci√≥n de Iris', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entrenar Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,  # N√∫mero de √°rboles\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Precisi√≥n del Random Forest: {accuracy_rf:.4f} ({accuracy_rf*100:.2f}%)\")\n",
    "\n",
    "# Importancia de caracter√≠sticas\n",
    "importancias = rf_model.feature_importances_\n",
    "indices = np.argsort(importancias)[::-1]\n",
    "\n",
    "print(\"\\n=== IMPORTANCIA DE CARACTER√çSTICAS ===\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i+1}. {iris.feature_names[idx]}: {importancias[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar importancia de caracter√≠sticas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(importancias)), importancias[indices], color='steelblue')\n",
    "plt.yticks(range(len(importancias)), \n",
    "           [iris.feature_names[i] for i in indices])\n",
    "plt.xlabel('Importancia')\n",
    "plt.title('Importancia de Caracter√≠sticas - Random Forest', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6. Clustering - K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizar datos (importante para K-Means)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris.data)\n",
    "\n",
    "# M√©todo del codo para encontrar K √≥ptimo\n",
    "inertias = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Visualizar m√©todo del codo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('N√∫mero de Clusters (K)')\n",
    "plt.ylabel('Inercia')\n",
    "plt.title('M√©todo del Codo para Determinar K √ìptimo', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar K-Means con K=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Visualizar clusters (usando primeras 2 caracter√≠sticas)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, \n",
    "            cmap='viridis', s=100, alpha=0.6, edgecolors='black')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], \n",
    "            kmeans.cluster_centers_[:, 1],\n",
    "            c='red', s=300, marker='X', \n",
    "            edgecolors='black', linewidths=2,\n",
    "            label='Centroides')\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.title('K-Means Clustering (Caracter√≠sticas 0-1)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_scaled[:, 2], X_scaled[:, 3], c=clusters, \n",
    "            cmap='viridis', s=100, alpha=0.6, edgecolors='black')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 2], \n",
    "            kmeans.cluster_centers_[:, 3],\n",
    "            c='red', s=300, marker='X', \n",
    "            edgecolors='black', linewidths=2,\n",
    "            label='Centroides')\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "plt.ylabel(iris.feature_names[3])\n",
    "plt.title('K-Means Clustering (Caracter√≠sticas 2-3)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparar con especies reales\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari = adjusted_rand_score(iris.target, clusters)\n",
    "print(f\"\\nAdjusted Rand Index: {ari:.4f}\")\n",
    "print(\"(Mide similitud entre clustering y clases reales, 1=perfecto)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7. Validaci√≥n Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "\n",
    "# Validaci√≥n cruzada con diferentes modelos\n",
    "modelos = {\n",
    "    'Regresi√≥n Log√≠stica': LogisticRegression(max_iter=200),\n",
    "    '√Årbol de Decisi√≥n': DecisionTreeClassifier(max_depth=3, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"=== VALIDACI√ìN CRUZADA (5-Fold) ===\")\n",
    "print()\n",
    "\n",
    "resultados = {}\n",
    "for nombre, modelo in modelos.items():\n",
    "    scores = cross_val_score(modelo, iris.data, iris.target, \n",
    "                            cv=5, scoring='accuracy')\n",
    "    resultados[nombre] = scores\n",
    "    \n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"  Scores: {scores}\")\n",
    "    print(f\"  Media: {scores.mean():.4f}\")\n",
    "    print(f\"  Desv. Std: {scores.std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados de validaci√≥n cruzada\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "nombres = list(resultados.keys())\n",
    "datos_box = [resultados[nombre] for nombre in nombres]\n",
    "\n",
    "bp = plt.boxplot(datos_box, labels=nombres, patch_artist=True)\n",
    "for patch, color in zip(bp['boxes'], ['lightblue', 'lightgreen', 'lightcoral']):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparaci√≥n de Modelos - Validaci√≥n Cruzada 5-Fold', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.ylim(0.8, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. TensorFlow/Keras - Deep Learning\n",
    "\n",
    "**TensorFlow** es la librer√≠a de Google para Deep Learning. **Keras** es su API de alto nivel.\n",
    "\n",
    "### ¬øPor qu√© TensorFlow/Keras?\n",
    "- **Potencia:** Redes neuronales profundas y complejas\n",
    "- **Facilidad:** Keras hace Deep Learning accesible\n",
    "- **Flexibilidad:** Desde prototipos r√°pidos hasta producci√≥n\n",
    "- **GPU:** Aceleraci√≥n autom√°tica con GPU\n",
    "- **Comunidad:** Enorme ecosistema y recursos\n",
    "\n",
    "### Instalaci√≥n\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Red Neuronal Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Preparar datos de Iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizar caracter√≠sticas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convertir etiquetas a formato one-hot\n",
    "y_train_cat = keras.utils.to_categorical(y_train, 3)\n",
    "y_test_cat = keras.utils.to_categorical(y_test, 3)\n",
    "\n",
    "print(f\"Shape de X_train: {X_train_scaled.shape}\")\n",
    "print(f\"Shape de y_train: {y_train_cat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear red neuronal\n",
    "model = models.Sequential([\n",
    "    layers.Dense(16, activation='relu', input_shape=(4,)),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar modelo\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Resumen del modelo\n",
    "print(\"=== ARQUITECTURA DEL MODELO ===\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    verbose=0  # No mostrar progreso detallado\n",
    ")\n",
    "\n",
    "print(\"Entrenamiento completado!\")\n",
    "\n",
    "# Evaluar modelo\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test_cat, verbose=0)\n",
    "print(f\"\\nPrecisi√≥n en test: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curvas de aprendizaje\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Precisi√≥n\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_accuracy'], label='Validaci√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Precisi√≥n del Modelo')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# P√©rdida\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Validaci√≥n')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('P√©rdida del Modelo')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Red Neuronal Convolucional (CNN) - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset MNIST (d√≠gitos escritos a mano)\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
    "\n",
    "print(f\"Shape de entrenamiento: {X_train_mnist.shape}\")\n",
    "print(f\"Shape de test: {X_test_mnist.shape}\")\n",
    "\n",
    "# Visualizar algunos ejemplos\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_train_mnist[i], cmap='gray')\n",
    "    plt.title(f'Etiqueta: {y_train_mnist[i]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Ejemplos del Dataset MNIST', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesar datos\n",
    "# Normalizar a rango [0, 1]\n",
    "X_train_mnist = X_train_mnist.astype('float32') / 255.0\n",
    "X_test_mnist = X_test_mnist.astype('float32') / 255.0\n",
    "\n",
    "# A√±adir dimensi√≥n del canal\n",
    "X_train_mnist = X_train_mnist.reshape(-1, 28, 28, 1)\n",
    "X_test_mnist = X_test_mnist.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# One-hot encoding para etiquetas\n",
    "y_train_mnist = keras.utils.to_categorical(y_train_mnist, 10)\n",
    "y_test_mnist = keras.utils.to_categorical(y_test_mnist, 10)\n",
    "\n",
    "print(f\"Shape final X_train: {X_train_mnist.shape}\")\n",
    "print(f\"Shape final y_train: {y_train_mnist.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear CNN\n",
    "cnn_model = models.Sequential([\n",
    "    # Primera capa convolucional\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Segunda capa convolucional\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Tercera capa convolucional\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    \n",
    "    # Capas densas\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Prevenir overfitting\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"=== ARQUITECTURA CNN ===\")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar CNN (solo 5 √©pocas para demostraci√≥n)\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_train_mnist[:10000], y_train_mnist[:10000],  # Subset para rapidez\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "test_loss, test_accuracy = cnn_model.evaluate(\n",
    "    X_test_mnist[:2000], y_test_mnist[:2000], \n",
    "    verbose=0\n",
    ")\n",
    "print(f\"\\nPrecisi√≥n en test: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones\n",
    "predicciones = cnn_model.predict(X_test_mnist[:10])\n",
    "predicciones_clases = np.argmax(predicciones, axis=1)\n",
    "verdaderos = np.argmax(y_test_mnist[:10], axis=1)\n",
    "\n",
    "# Visualizar predicciones\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(X_test_mnist[i].reshape(28, 28), cmap='gray')\n",
    "    color = 'green' if predicciones_clases[i] == verdaderos[i] else 'red'\n",
    "    plt.title(f'P: {predicciones_clases[i]}\\nV: {verdaderos[i]}', color=color)\n",
    "    plt.axis('off')\n",
    "plt.suptitle('Predicciones CNN (Verde=Correcto, Rojo=Error)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. PyTorch - Deep Learning Avanzado\n",
    "\n",
    "**PyTorch** es la librer√≠a de Facebook para Deep Learning, especialmente popular en investigaci√≥n.\n",
    "\n",
    "### ¬øPor qu√© PyTorch?\n",
    "- **Pythonic:** Sintaxis intuitiva y f√°cil de debuggear\n",
    "- **Din√°mico:** Grafos computacionales din√°micos\n",
    "- **Investigaci√≥n:** Preferido en papers acad√©micos\n",
    "- **GPU:** F√°cil transici√≥n entre CPU y GPU\n",
    "- **Flexibilidad:** Control total sobre el proceso\n",
    "\n",
    "### Instalaci√≥n\n",
    "```bash\n",
    "pip install torch torchvision\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Tensores en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Crear tensores\n",
    "tensor1 = torch.tensor([1, 2, 3, 4])\n",
    "tensor2 = torch.zeros(3, 4)\n",
    "tensor3 = torch.randn(2, 3)  # Distribuci√≥n normal\n",
    "\n",
    "print(\"\\nTensor 1:\")\n",
    "print(tensor1)\n",
    "print(f\"Shape: {tensor1.shape}, dtype: {tensor1.dtype}\")\n",
    "\n",
    "print(\"\\nTensor 2 (ceros):\")\n",
    "print(tensor2)\n",
    "\n",
    "print(\"\\nTensor 3 (aleatorio):\")\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operaciones con tensores\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"Tensor a:\", a)\n",
    "print(\"Tensor b:\", b)\n",
    "print(f\"\\na + b = {a + b}\")\n",
    "print(f\"a * b = {a * b}\")\n",
    "print(f\"a @ b = {torch.dot(a, b)}\")\n",
    "\n",
    "# Operaciones matriciales\n",
    "matriz1 = torch.randn(3, 4)\n",
    "matriz2 = torch.randn(4, 2)\n",
    "producto = torch.mm(matriz1, matriz2)  # Multiplicaci√≥n matricial\n",
    "\n",
    "print(f\"\\nMatriz 1 shape: {matriz1.shape}\")\n",
    "print(f\"Matriz 2 shape: {matriz2.shape}\")\n",
    "print(f\"Producto shape: {producto.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2. Red Neuronal Simple en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RedNeuronal, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "modelo_torch = RedNeuronal(input_size=4, hidden_size=16, output_size=3)\n",
    "print(\"=== MODELO PYTORCH ===\")\n",
    "print(modelo_torch)\n",
    "\n",
    "# Contar par√°metros\n",
    "total_params = sum(p.numel() for p in modelo_torch.parameters())\n",
    "print(f\"\\nTotal de par√°metros: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para PyTorch\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Crear DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(f\"N√∫mero de batches: {len(train_loader)}\")\n",
    "print(f\"Tama√±o de batch: 16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir funci√≥n de p√©rdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modelo_torch.parameters(), lr=0.01)\n",
    "\n",
    "# Entrenar modelo\n",
    "num_epochs = 100\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = modelo_torch(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass y optimizaci√≥n\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    losses.append(epoch_loss / len(train_loader))\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"√âpoca [{epoch+1}/{num_epochs}], Loss: {losses[-1]:.4f}\")\n",
    "\n",
    "print(\"\\nEntrenamiento completado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo\n",
    "modelo_torch.eval()  # Modo evaluaci√≥n\n",
    "with torch.no_grad():\n",
    "    outputs = modelo_torch(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).float().mean()\n",
    "\n",
    "print(f\"Precisi√≥n en test: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "\n",
    "# Visualizar curva de p√©rdida\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(losses, linewidth=2)\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Curva de Aprendizaje - PyTorch', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3. CNN en PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Capas convolucionales\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Capas fully connected\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convoluciones\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        \n",
    "        # Fully connected\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "cnn_torch = CNN()\n",
    "print(\"=== CNN PYTORCH ===\")\n",
    "print(cnn_torch)\n",
    "\n",
    "total_params = sum(p.numel() for p in cnn_torch.parameters())\n",
    "print(f\"\\nTotal de par√°metros: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Proyecto Integrador Final\n",
    "\n",
    "### An√°lisis Completo: Predicci√≥n de Precios de Casas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset sint√©tico de precios de casas\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# Generar caracter√≠sticas\n",
    "superficie = np.random.randint(50, 300, n_samples)\n",
    "habitaciones = np.random.randint(1, 6, n_samples)\n",
    "banos = np.random.randint(1, 4, n_samples)\n",
    "antiguedad = np.random.randint(0, 50, n_samples)\n",
    "distancia_centro = np.random.uniform(0, 20, n_samples)\n",
    "\n",
    "# Generar precio (con cierta relaci√≥n con las caracter√≠sticas)\n",
    "precio = (\n",
    "    superficie * 1000 + \n",
    "    habitaciones * 15000 + \n",
    "    banos * 20000 - \n",
    "    antiguedad * 500 - \n",
    "    distancia_centro * 2000 +\n",
    "    np.random.randn(n_samples) * 20000\n",
    ")\n",
    "\n",
    "# Crear DataFrame\n",
    "casas_df = pd.DataFrame({\n",
    "    'superficie': superficie,\n",
    "    'habitaciones': habitaciones,\n",
    "    'banos': banos,\n",
    "    'antiguedad': antiguedad,\n",
    "    'distancia_centro': distancia_centro,\n",
    "    'precio': precio\n",
    "})\n",
    "\n",
    "print(\"=== DATASET DE CASAS ===\")\n",
    "print(casas_df.head(10))\n",
    "print(f\"\\nForma: {casas_df.shape}\")\n",
    "print(\"\\nEstad√≠sticas:\")\n",
    "print(casas_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EXPLORACI√ìN CON SEABORN\n",
    "print(\"=== FASE 1: EXPLORACI√ìN DE DATOS ===\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Distribuci√≥n de precios\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "sns.histplot(data=casas_df, x='precio', kde=True, color='steelblue', ax=ax1)\n",
    "ax1.set_title('Distribuci√≥n de Precios', fontweight='bold')\n",
    "\n",
    "# Precio vs Superficie\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "sns.scatterplot(data=casas_df, x='superficie', y='precio', \n",
    "                hue='habitaciones', palette='viridis', ax=ax2)\n",
    "ax2.set_title('Precio vs Superficie', fontweight='bold')\n",
    "\n",
    "# Matriz de correlaci√≥n\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "corr_casas = casas_df.corr()\n",
    "sns.heatmap(corr_casas, annot=True, cmap='coolwarm', center=0, ax=ax3,\n",
    "            square=True)\n",
    "ax3.set_title('Matriz de Correlaci√≥n', fontweight='bold')\n",
    "\n",
    "# Precio por habitaciones\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "sns.boxplot(data=casas_df, x='habitaciones', y='precio', palette='Set2', ax=ax4)\n",
    "ax4.set_title('Precio por Habitaciones', fontweight='bold')\n",
    "\n",
    "# Precio vs Antig√ºedad\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "sns.scatterplot(data=casas_df, x='antiguedad', y='precio', \n",
    "                alpha=0.5, color='coral', ax=ax5)\n",
    "sns.regplot(data=casas_df, x='antiguedad', y='precio', \n",
    "            scatter=False, color='darkred', ax=ax5)\n",
    "ax5.set_title('Precio vs Antig√ºedad', fontweight='bold')\n",
    "\n",
    "# Pairplot subset\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "ax6.axis('off')\n",
    "ax6.text(0.5, 0.5, 'Ver Pairplot\\nabajo', \n",
    "         ha='center', va='center', fontsize=14)\n",
    "\n",
    "plt.suptitle('An√°lisis Exploratorio - Precios de Casas', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Pairplot\n",
    "sns.pairplot(casas_df.sample(200), \n",
    "             vars=['superficie', 'habitaciones', 'precio'],\n",
    "             height=3)\n",
    "plt.suptitle('Relaciones entre Variables Clave', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MACHINE LEARNING CON SCIKIT-LEARN\n",
    "print(\"\\n=== FASE 2: MODELOS DE MACHINE LEARNING ===\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Preparar datos\n",
    "X = casas_df.drop('precio', axis=1).values\n",
    "y = casas_df['precio'].values\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalizar\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entrenar m√∫ltiples modelos\n",
    "modelos_ml = {\n",
    "    'Regresi√≥n Lineal': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=10),\n",
    "    'Lasso': Lasso(alpha=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "resultados_ml = {}\n",
    "\n",
    "print(\"\\nEntrenando modelos...\\n\")\n",
    "for nombre, modelo in modelos_ml.items():\n",
    "    # Entrenar\n",
    "    modelo.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predecir\n",
    "    y_pred = modelo.predict(X_test_scaled)\n",
    "    \n",
    "    # M√©tricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    resultados_ml[nombre] = {\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'predicciones': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"  RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"  MAE:  ${mae:,.2f}\")\n",
    "    print(f\"  R¬≤:   {r2:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar comparaci√≥n de modelos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (nombre, resultados) in enumerate(resultados_ml.items()):\n",
    "    ax = axes[i]\n",
    "    y_pred = resultados['predicciones']\n",
    "    \n",
    "    # Scatter plot: real vs predicho\n",
    "    ax.scatter(y_test, y_pred, alpha=0.5)\n",
    "    ax.plot([y_test.min(), y_test.max()], \n",
    "            [y_test.min(), y_test.max()], \n",
    "            'r--', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Precio Real')\n",
    "    ax.set_ylabel('Precio Predicho')\n",
    "    ax.set_title(f\"{nombre}\\nR¬≤ = {resultados['R¬≤']:.3f}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "axes[5].axis('off')\n",
    "plt.suptitle('Comparaci√≥n de Modelos ML - Predicci√≥n de Precios', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaci√≥n de m√©tricas\n",
    "metricas_df = pd.DataFrame({\n",
    "    nombre: {\n",
    "        'RMSE': resultados['RMSE'],\n",
    "        'MAE': resultados['MAE'],\n",
    "        'R¬≤': resultados['R¬≤']\n",
    "    }\n",
    "    for nombre, resultados in resultados_ml.items()\n",
    "}).T\n",
    "\n",
    "print(\"\\n=== COMPARACI√ìN DE MODELOS ===\")\n",
    "print(metricas_df.sort_values('R¬≤', ascending=False))\n",
    "\n",
    "# Visualizar comparaci√≥n\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for i, metrica in enumerate(['RMSE', 'MAE', 'R¬≤']):\n",
    "    ax = axes[i]\n",
    "    metricas_df[metrica].sort_values().plot(kind='barh', ax=ax, color='steelblue')\n",
    "    ax.set_title(f'{metrica} por Modelo', fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DEEP LEARNING CON TENSORFLOW/KERAS\n",
    "print(\"\\n=== FASE 3: DEEP LEARNING ===\")\n",
    "\n",
    "# Crear modelo de red neuronal\n",
    "dl_model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(5,)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1)  # Regresi√≥n: 1 salida\n",
    "])\n",
    "\n",
    "dl_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print(\"\\n=== ARQUITECTURA DE LA RED NEURONAL ===\")\n",
    "dl_model.summary()\n",
    "\n",
    "# Entrenar\n",
    "print(\"\\nEntrenando red neuronal...\")\n",
    "history_dl = dl_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Entrenamiento completado!\")\n",
    "\n",
    "# Evaluar\n",
    "y_pred_dl = dl_model.predict(X_test_scaled, verbose=0).flatten()\n",
    "mse_dl = mean_squared_error(y_test, y_pred_dl)\n",
    "rmse_dl = np.sqrt(mse_dl)\n",
    "mae_dl = mean_absolute_error(y_test, y_pred_dl)\n",
    "r2_dl = r2_score(y_test, y_pred_dl)\n",
    "\n",
    "print(f\"\\n=== RESULTADOS DEEP LEARNING ===\")\n",
    "print(f\"RMSE: ${rmse_dl:,.2f}\")\n",
    "print(f\"MAE:  ${mae_dl:,.2f}\")\n",
    "print(f\"R¬≤:   {r2_dl:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar curvas de aprendizaje y resultados\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Curva de p√©rdida\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.plot(history_dl.history['loss'], label='Entrenamiento')\n",
    "ax1.plot(history_dl.history['val_loss'], label='Validaci√≥n')\n",
    "ax1.set_xlabel('√âpoca')\n",
    "ax1.set_ylabel('MSE Loss')\n",
    "ax1.set_title('Curva de P√©rdida', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Curva de MAE\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax2.plot(history_dl.history['mae'], label='Entrenamiento')\n",
    "ax2.plot(history_dl.history['val_mae'], label='Validaci√≥n')\n",
    "ax2.set_xlabel('√âpoca')\n",
    "ax2.set_ylabel('MAE')\n",
    "ax2.set_title('Error Absoluto Medio', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Predicciones vs Real\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.scatter(y_test, y_pred_dl, alpha=0.5)\n",
    "ax3.plot([y_test.min(), y_test.max()], \n",
    "         [y_test.min(), y_test.max()], \n",
    "         'r--', linewidth=2)\n",
    "ax3.set_xlabel('Precio Real')\n",
    "ax3.set_ylabel('Precio Predicho')\n",
    "ax3.set_title(f'Deep Learning\\nR¬≤ = {r2_dl:.3f}', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Comparaci√≥n final de todos los modelos\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "todos_modelos = list(resultados_ml.keys()) + ['Deep Learning']\n",
    "todos_r2 = [resultados_ml[m]['R¬≤'] for m in resultados_ml.keys()] + [r2_dl]\n",
    "colores = ['steelblue'] * len(resultados_ml) + ['coral']\n",
    "bars = ax4.barh(todos_modelos, todos_r2, color=colores)\n",
    "ax4.set_xlabel('R¬≤ Score')\n",
    "ax4.set_title('Comparaci√≥n Final - Todos los Modelos', fontweight='bold')\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# A√±adir valores en las barras\n",
    "for i, (bar, valor) in enumerate(zip(bars, todos_r2)):\n",
    "    ax4.text(valor, i, f' {valor:.3f}', \n",
    "             va='center', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Resultados Finales - Deep Learning', \n",
    "             fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCLUSIONES FINALES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONCLUSIONES DEL PROYECTO INTEGRADOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Mejor modelo\n",
    "mejor_modelo_ml = max(resultados_ml.items(), \n",
    "                      key=lambda x: x[1]['R¬≤'])\n",
    "\n",
    "print(f\"\\nüìä MEJOR MODELO ML: {mejor_modelo_ml[0]}\")\n",
    "print(f\"   R¬≤: {mejor_modelo_ml[1]['R¬≤']:.4f}\")\n",
    "print(f\"   RMSE: ${mejor_modelo_ml[1]['RMSE']:,.2f}\")\n",
    "\n",
    "print(f\"\\nüß† DEEP LEARNING:\")\n",
    "print(f\"   R¬≤: {r2_dl:.4f}\")\n",
    "print(f\"   RMSE: ${rmse_dl:,.2f}\")\n",
    "\n",
    "if r2_dl > mejor_modelo_ml[1]['R¬≤']:\n",
    "    print(f\"\\n‚úÖ Deep Learning SUPERA a ML tradicional\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ {mejor_modelo_ml[0]} es el MEJOR modelo\")\n",
    "\n",
    "print(f\"\\nüìà LIBRER√çAS UTILIZADAS:\")\n",
    "print(f\"   ‚Ä¢ NumPy: Computaci√≥n num√©rica\")\n",
    "print(f\"   ‚Ä¢ Pandas: Manipulaci√≥n de datos\")\n",
    "print(f\"   ‚Ä¢ Matplotlib: Visualizaci√≥n b√°sica\")\n",
    "print(f\"   ‚Ä¢ Seaborn: Visualizaci√≥n estad√≠stica\")\n",
    "print(f\"   ‚Ä¢ Scikit-learn: Machine Learning\")\n",
    "print(f\"   ‚Ä¢ TensorFlow/Keras: Deep Learning\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIN DEL PROYECTO\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Resumen Final\n",
    "\n",
    "### Scikit-learn\n",
    "- **Regresi√≥n:** LinearRegression, Ridge, Lasso\n",
    "- **Clasificaci√≥n:** LogisticRegression, DecisionTree, RandomForest\n",
    "- **Clustering:** K-Means, DBSCAN\n",
    "- **Validaci√≥n:** train_test_split, cross_val_score\n",
    "- **M√©tricas:** accuracy, precision, recall, r2_score\n",
    "\n",
    "### TensorFlow/Keras\n",
    "- **Secuencial:** models.Sequential para redes simples\n",
    "- **Capas:** Dense, Conv2D, MaxPooling, Dropout\n",
    "- **Compilaci√≥n:** optimizer, loss, metrics\n",
    "- **Entrenamiento:** fit(), evaluate(), predict()\n",
    "- **Callbacks:** EarlyStopping, ModelCheckpoint\n",
    "\n",
    "### PyTorch\n",
    "- **Tensores:** torch.tensor, operaciones GPU\n",
    "- **M√≥dulos:** nn.Module, nn.Linear, nn.Conv2d\n",
    "- **Optimizaci√≥n:** optim.Adam, optim.SGD\n",
    "- **Entrenamiento:** Forward pass, backward pass, optimizaci√≥n\n",
    "- **DataLoader:** Gesti√≥n eficiente de datos\n",
    "\n",
    "### Flujo de Trabajo Completo\n",
    "```python\n",
    "1. Cargar datos (Pandas)\n",
    "2. Explorar y visualizar (Seaborn, Matplotlib)\n",
    "3. Limpiar y preparar (NumPy, Pandas)\n",
    "4. Dividir train/test (Scikit-learn)\n",
    "5. Entrenar modelos ML (Scikit-learn)\n",
    "6. Entrenar Deep Learning (TensorFlow/PyTorch)\n",
    "7. Evaluar y comparar (M√©tricas)\n",
    "8. Visualizar resultados (Matplotlib, Seaborn)\n",
    "9. Seleccionar mejor modelo\n",
    "10. Desplegar a producci√≥n\n",
    "```\n",
    "\n",
    "### Cu√°ndo Usar Cada Librer√≠a\n",
    "\n",
    "**NumPy:** Operaciones num√©ricas, √°lgebra lineal\n",
    "\n",
    "**Pandas:** Datos tabulares, an√°lisis exploratorio\n",
    "\n",
    "**Matplotlib:** Visualizaciones personalizadas, control total\n",
    "\n",
    "**Seaborn:** Visualizaciones estad√≠sticas r√°pidas y hermosas\n",
    "\n",
    "**Scikit-learn:** ML tradicional, datasets peque√±os-medianos\n",
    "\n",
    "**TensorFlow/Keras:** Deep Learning, producci√≥n, datasets grandes\n",
    "\n",
    "**PyTorch:** Investigaci√≥n, prototipos, control fino\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
